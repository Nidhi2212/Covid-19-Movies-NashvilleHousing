# Covid-19 Statistics 
### Introduction

**<div align = "justify">**
This readme describes the work done on the  **Covid-19 Dataset** which is downloaded from https://ourworldindata.org. Dataset is separated into _Covid-19 Vaccinations_ and _Covid-19 Deaths_ to perform exploratory analysis and create visualizations.


<div align = "justify">
SQL is used to conduct exploratory analysis. Firstly, 2 tables for uploading dataset saved in .csv format are created in MySQL Workbench. Afterwards, different queries to calculate Death Percentage, Contract Percentage, Percentage of Population Infected, Percentage of Population Died, and Highest Death Count per Continent are executed.

<br/>
<div align = "justify">
Tableau is used for converting above results into visuals. Since Tableau Public cannot be connected with SQL, different set of queries are written for Tableau and the results are saved into MS Excel sheets which are then uploaded to Tableau for creating visuals.

* SQL queries can be found here: [SQL Queries](https://github.com/Nidhi2212/Covid-19.git)


* Tableau Dashboard can be viewed here: [Covid-19 Visualization](https://public.tableau.com/app/profile/nidhi.gupta7518/viz/PortfolioProject-Covid_16735363014950/Dashboard1)


# Movies Data (1986 - 2016)
### Introduction

**<div align = "justify">**
This readme describes the work done on the  **Movies Dataset** which is downloaded from https://www.kaggle.com/datasets/danielgrijalvas/movies.


<div align = "justify">
Python is used to clean the data and then conduct exploratory analysis and create visualizations. Firstly, the libraries which are to be used in Python for mentioned analysis are imported and then dataset in .csv format is uploaded. Afterwards, different queries to view the data, change the data type of columns, extract year from the release data column and create line, scatter plot and heatmap using different columns are executed.

**<br/>**
Python code can be found here: [Python](https://github.com/Nidhi2212/Movies-1986-2016.git)

# Data Cleaning with Housing Dataset using SQL
### Introduction

**<div align = "justify">**
This readme describes the work done on the  **Nashville Housing Dataset**.

<div align = "justify">
SQL is used to clean the data. Firstly, a table for uploading dataset saved in .csv format is created in MySQL Workbench. Afterwards, different queries are written to make the dataset useful for further analysis. Data is cleaned by standardizing the date columns, populating blanks in Address column, separating City and State from Address, removing duplicate rows and finally, removing unused columns.

**<br/>**
SQL queries can be found here: [SQL Queries](https://github.com/Nidhi2212/Nashville-Housing-Data.git)

